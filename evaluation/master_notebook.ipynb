{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import sklearn\n",
    "from sklearn import metrics, utils, ensemble\n",
    "from joblib import Parallel, delayed\n",
    "import time \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# TODO: CHANGE INSTITUTION NAME\n",
    "institution = 'INSTITUTION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input:  {INSTITUTION}-MASTER.csv\n",
    "# Output: {INSTITUTION}-RESULTS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in data\n",
    "master = pd.read_csv('{}-MASTER.csv'.format(institution))\n",
    "\n",
    "req_cols = set(['hosp_id', 'y', 'y_score_fourvar', 'y_score_mcures',\n",
    "                'y_scores_four_lst', 'y_scores_mcures_lst', 'race', 'age', 'sex', 'ethnicity',\n",
    "                'outcome', 'outcome_time', 'admission_date',\n",
    "                'final_time_min'])\n",
    "\n",
    "master = master[req_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse outcome scores for primary use case\n",
    "from ast import literal_eval\n",
    "\n",
    "master[\"y_scores_mcures_lst_\"] = master[\"y_scores_mcures_lst\"].apply(literal_eval)\n",
    "master[\"y_scores_mcures_lst_eval1\"] = master[\"y_scores_mcures_lst_\"].apply(lambda L: L[1:]) # Exclude first window\n",
    "\n",
    "master[\"y_scores_four_lst_\"] = master[\"y_scores_four_lst\"].apply(literal_eval)\n",
    "master[\"y_scores_four_lst_eval1\"] = master[\"y_scores_four_lst_\"].apply(lambda L: L[1:]) # Exclude first window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scores for secondary use case\n",
    "in_second_case = (master['final_time_min'] > 2880).values\n",
    "master['in_second_use_case'] = in_second_case\n",
    "\n",
    "secondary_four = [np.mean(x[0:12]) if master['in_second_use_case'][i] else np.nan for i,x in enumerate(master['y_scores_four_lst_'].values)]\n",
    "mcures_four = [np.mean(x[0:12]) if master['in_second_use_case'][i] else np.nan for i,x in enumerate(master['y_scores_mcures_lst_'].values)]\n",
    "\n",
    "master['secondary_four'] = secondary_four\n",
    "master['secondary_mcures'] = mcures_four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondary use case y value \n",
    "\n",
    "master['y_secondary'] = (1 - np.isnan(master['outcome_time'])).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error checking helper functions\n",
    "def check_allowed_categories(observed, allowed):\n",
    "    observed = set(observed)\n",
    "    allowed = set(allowed)\n",
    "    intersection = observed.intersection(allowed)\n",
    "    \n",
    "    if observed != intersection:\n",
    "        non_allowed = observed-allowed\n",
    "        print(\"observed non-allowed categories: {}\".format(', '.join([str(i) for i in non_allowed])))\n",
    "        return(False)\n",
    "    else:\n",
    "        return(True)\n",
    "\n",
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text\n",
    "\n",
    "def unpack_lists(col_as_list):\n",
    "    unpacked_list = []\n",
    "    for i in col_as_list:\n",
    "        #print(i)\n",
    "        if type(i)==list:\n",
    "            i = ','.join([str(j) for j in i])\n",
    "        i = replace_all(i, {'[': '', ']':''})\n",
    "        i = i.strip().split(',')\n",
    "        i = [float(j.strip()) for j in i]\n",
    "        unpacked_list.append(i)\n",
    "    \n",
    "    return(unpacked_list)\n",
    "\n",
    "def check_list_lengths(lol1, lol2):\n",
    "    #lol = list of lists\n",
    "    for i,j in zip(lol1, lol2):\n",
    "        if len(i)!=len(j):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def check_reference(lol, ref, list_op=max, eps=None):\n",
    "    for idx, (i,j) in enumerate(zip(lol, ref)):\n",
    "        _val = list_op(i)\n",
    "        if eps is None:\n",
    "            if _val!=j:\n",
    "                print(idx, '\\n', i, '\\n' , j, _val, j in i, '\\n')\n",
    "                return False\n",
    "        elif abs(_val-j)>eps:\n",
    "            print(idx, '\\n', i, '\\n' , j, _val, j in i, '\\n')\n",
    "            return False\n",
    "            \n",
    "    return True\n",
    "\n",
    "\n",
    "print(\"All Columns\")\n",
    "req_cols = set(['hosp_id', 'y', 'y_score_fourvar', 'y_score_mcures',\n",
    "                'y_scores_four_lst', 'y_scores_mcures_lst', 'race', 'age', 'sex',\n",
    "                'outcome', 'outcome_time', 'admission_date',\n",
    "                'final_time_min'])\n",
    "\n",
    "r = (req_cols == set(master.columns).intersection(req_cols))\n",
    "print(\"\\tHave all required columns? {}\".format(r))\n",
    "\n",
    "\n",
    "print(\"Age\")\n",
    "r = (master[\"age\"].dtype == int)\n",
    "print(\"\\tIs integer? {}\".format(r))\n",
    "r = (master[\"age\"].min()>=18)\n",
    "print(\"\\tMin>=18? {}\".format(r))\n",
    "r = (master[\"age\"].max()<=90)\n",
    "print(\"\\tMax<=90? {}\".format(r))\n",
    "\n",
    "print(\"Encounters w/ Outcome\")\n",
    "_ = master[master[\"y\"]==1]\n",
    "r = ( (_[\"final_time_min\"] - _[\"outcome_time\"]).sum() == 0)\n",
    "print(\"\\tfinal_time equals outcome_time? {}\".format(r))\n",
    "allowed_outcomes = ['HHFNC', 'MV', 'mortality', 'IV']\n",
    "r = check_allowed_categories(_[\"outcome\"].unique(), allowed_outcomes)\n",
    "print(\"\\tOnly use allowed outcomes? {}\".format(r))\n",
    "\n",
    "print(\"Race\")\n",
    "allowed_races = [\"African American\", \"American Indian or Alaska Native\", \"Asian\", \"Caucasian\", \"Native Hawaiian and Other Pacific Islander\", \"Other\", \"Patient Refused\", \"Unknown\", \"More than 1\", np.nan]\n",
    "r = check_allowed_categories(master[\"race\"].unique(), allowed_races)\n",
    "print(\"\\tOnly use allowed race categories? {}\".format(r))\n",
    "\n",
    "print(\"Sex\")\n",
    "allowed_sexes = [\"F\", \"M\"]\n",
    "r = check_allowed_categories(master[\"sex\"].unique(), allowed_sexes)\n",
    "print(\"\\tOnly use allowed sex categories? {}\".format(r))\n",
    "\n",
    "print(\"Ethnicity\")\n",
    "allowed_ethnicities = [\"Hispanic or Latino\", \"Non-Hispanic or Latino\", \"Patient Refused\", \"Unknown\"]\n",
    "# r= check_allowed_categories(master[\"ethnicity\"].unique(), allowed_ethnicities)\n",
    "#print(\"\\tOnly use allowed ethnicity categories? {}\".format(r))\n",
    "print(\"\\tUncomment above to do check.\")\n",
    "\n",
    "list_cns = [\"y_scores_four_lst\", \"y_scores_mcures_lst\", \"y_scores_mcures_lst_\", \"y_scores_mcures_lst_eval1\", \"y_scores_four_lst_\", \"y_scores_four_lst_eval1\"]\n",
    "unpacked_list_dict = {cn: unpack_lists(list(master[cn])) for cn in list_cns}\n",
    "nwin = [min(i, 30) for i in list(np.floor(master[\"final_time_min\"]/(4*60)))]\n",
    "\n",
    "print(\"Lists\")\n",
    "r = check_list_lengths(unpacked_list_dict[\"y_scores_four_lst\"], unpacked_list_dict[\"y_scores_mcures_lst\"])\n",
    "print(\"\\tScore lists the same length? {}\".format(r))\n",
    "r = check_list_lengths(unpacked_list_dict[\"y_scores_four_lst_eval1\"], unpacked_list_dict[\"y_scores_mcures_lst_eval1\"])\n",
    "print(\"\\tScore (eval1) lists the same length? {}\".format(r))\n",
    "\n",
    "r = check_reference(unpacked_list_dict[\"y_scores_four_lst_eval1\"], list(master[\"y_score_fourvar\"]), eps=1E-10)\n",
    "print(\"\\tIs fourvar (eval1) max is max of list? {}\".format(r))\n",
    "r = check_reference(unpacked_list_dict[\"y_scores_mcures_lst_eval1\"], list(master[\"y_score_mcures\"]), eps=1E-10)\n",
    "print(\"\\tIs MCURES (eval1) max is max of list? {}\".format(r))\n",
    "\n",
    "r = check_reference(unpacked_list_dict[\"y_scores_four_lst\"], nwin, list_op=len)\n",
    "print(\"\\tIs len of fourvar equal to expected number of windows? {}\".format(r))\n",
    "r = check_reference(unpacked_list_dict[\"y_scores_four_lst_eval1\"], [i-1 for i in nwin], list_op=len)\n",
    "print(\"\\tIs len of fourvar (eval1) equal to expected number of windows-1? {}\".format(r))\n",
    "r = check_reference(unpacked_list_dict[\"y_scores_mcures_lst\"], nwin, list_op=len)\n",
    "print(\"\\tIs len of MCURES equal to expected number of windows? {}\".format(r))\n",
    "r = check_reference(unpacked_list_dict[\"y_scores_mcures_lst_eval1\"], [i-1 for i in nwin], list_op=len)\n",
    "print(\"\\tIs len of MCURES (eval1) equal to expected number of windows-1? {}\".format(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "def get_nums(df, string = 'y_score_mcures'): \n",
    "    N, perc, val_roc, all_rocs = get_roc(df['y'], df[string])\n",
    "    all_prs, val_pr = get_pr(df['y'], df[string])\n",
    "    return (N, perc), (all_rocs, val_roc), (all_prs, val_pr)\n",
    "\n",
    "def get_roc(y_true, y_score):\n",
    "    roc_curves, auc_scores = zip(*Parallel(n_jobs=4)(delayed(bootstrap_func_roc)(i, y_true, y_score) for i in range(1000)))\n",
    "    val = metrics.roc_auc_score(y_true, y_score)\n",
    "    return len(y_true), np.mean(y_true), val, auc_scores\n",
    "\n",
    "def bootstrap_func_roc(i, y_true, y_score):\n",
    "    while True:\n",
    "        try:\n",
    "            yte_true_b, yte_pred_b = utils.resample(y_true, y_score, replace=True, random_state=i)\n",
    "            return metrics.roc_curve(yte_true_b, yte_pred_b), metrics.roc_auc_score(yte_true_b, yte_pred_b)\n",
    "        except: \n",
    "            i += 1000\n",
    "\n",
    "def bootstrap_func_calib(i, combine_all_scores, all_ys):\n",
    "    yte_true_b, yte_pred_b = utils.resample(combine_all_scores, all_ys, replace=True, random_state=i)\n",
    "    flat_ys = [item for sublist in yte_pred_b for item in sublist]\n",
    "    flat_scores = [item for sublist in yte_true_b for item in sublist]\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(flat_ys, flat_scores, strategy = 'quantile')\n",
    "    return fraction_of_positives, mean_predicted_value \n",
    "\n",
    "            \n",
    "def get_calibs(combine_all_scores, all_ys):\n",
    "    fractions, means = zip(*Parallel(n_jobs=4)(delayed(bootstrap_func_calib)(i, combine_all_scores, all_ys) for i in range(1000)))\n",
    "    return fractions, means\n",
    "    \n",
    "def get_roc_CI(y_true, y_score):\n",
    "    roc_curves, auc_scores = zip(*Parallel(n_jobs=4)(delayed(bootstrap_func_roc)(i, y_true, y_score) for i in range(1000)))\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    for fpr, tpr, _ in roc_curves:\n",
    "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        aucs.append(metrics.auc(fpr, tpr))\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + 1.96 * std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - 1.96 * std_tpr, 0)\n",
    "    return roc_curves, auc_scores, mean_fpr, tprs_lower, tprs_upper\n",
    "\n",
    "def bootstrap_func_pr(i, y_true, y_score):\n",
    "    while True:\n",
    "        try:\n",
    "            yte_true_b, yte_pred_b = utils.resample(y_true, y_score, replace=True, random_state=i)\n",
    "            return (\n",
    "                metrics.precision_recall_curve(yte_true_b, yte_pred_b), \n",
    "                metrics.auc(*metrics.precision_recall_curve(yte_true_b, yte_pred_b)[1::-1])\n",
    "            )\n",
    "        except: \n",
    "            i += 1000\n",
    "\n",
    "def get_pr(y_true, y_score):\n",
    "    curves, scores = zip(*Parallel(n_jobs=4)(delayed(bootstrap_func_pr)(i, y_true, y_score) for i in range(1000)))\n",
    "    val = metrics.auc(*metrics.precision_recall_curve(y_true, y_score)[1::-1])\n",
    "    return scores, val\n",
    "\n",
    "def get_pr_CI(y_true, y_score):\n",
    "    curves, scores = zip(*Parallel(n_jobs=4)(delayed(bootstrap_func_pr)(i, y_true, y_score) for i in range(1000)))\n",
    "    precs = []\n",
    "    mean_rec = np.linspace(0, 1, 101)\n",
    "    for prec, rec, _ in curves:\n",
    "        rec_sorted, prec_sorted = rec[np.argsort(rec)], prec[np.argsort(rec)]\n",
    "        precs.append(np.interp(mean_rec, rec_sorted, prec_sorted))\n",
    "    mean_prec = np.mean(precs, axis=0)\n",
    "    std_prec = np.std(precs, axis=0)\n",
    "    prec_upper = np.minimum(mean_prec + 1.96 * std_prec, 1)\n",
    "    prec_lower = np.maximum(mean_prec - 1.96 * std_prec, 0)\n",
    "    return curves, scores, mean_rec, prec_lower, prec_upper\n",
    "\n",
    "from sklearn.utils import column_or_1d\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.utils.validation import check_consistent_length\n",
    "\n",
    "def calibration_curve_ece(y_true, y_prob, *, normalize=False, n_bins=5,\n",
    "                      strategy='uniform'):\n",
    "    y_true = column_or_1d(y_true)\n",
    "    y_prob = column_or_1d(y_prob)\n",
    "    check_consistent_length(y_true, y_prob)\n",
    "\n",
    "    if normalize:  # Normalize predicted values into interval [0, 1]\n",
    "        y_prob = (y_prob - y_prob.min()) / (y_prob.max() - y_prob.min())\n",
    "    elif y_prob.min() < 0 or y_prob.max() > 1:\n",
    "        raise ValueError(\"y_prob has values outside [0, 1] and normalize is \"\n",
    "                         \"set to False.\")\n",
    "\n",
    "    labels = np.unique(y_true)\n",
    "    if len(labels) > 2:\n",
    "        raise ValueError(\"Only binary classification is supported. \"\n",
    "                         \"Provided labels %s.\" % labels)\n",
    "    y_true = label_binarize(y_true, classes=labels)[:, 0]\n",
    "\n",
    "    if strategy == 'quantile':  # Determine bin edges by distribution of data\n",
    "        quantiles = np.linspace(0, 1, n_bins + 1)\n",
    "        bins = np.percentile(y_prob, quantiles * 100)\n",
    "        bins[-1] = bins[-1] + 1e-8\n",
    "    elif strategy == 'uniform':\n",
    "        bins = np.linspace(0., 1. + 1e-8, n_bins + 1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid entry to 'strategy' input. Strategy \"\n",
    "                         \"must be either 'quantile' or 'uniform'.\")\n",
    "\n",
    "    binids = np.digitize(y_prob, bins) - 1\n",
    "    bin_sums = np.bincount(binids, weights=y_prob, minlength=len(bins))\n",
    "    bin_true = np.bincount(binids, weights=y_true, minlength=len(bins))\n",
    "    bin_total = np.bincount(binids, minlength=len(bins))\n",
    "\n",
    "    nonzero = bin_total != 0\n",
    "    prob_true = bin_true[nonzero] / bin_total[nonzero]\n",
    "    prob_pred = bin_sums[nonzero] / bin_total[nonzero]\n",
    "\n",
    "    return np.sum((np.bincount(binids) / sum(np.bincount(binids))) * np.abs(prob_true - prob_pred))\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "def fsgte(score_fx, df, thresholds=None):\n",
    "    given_thresholds = thresholds\n",
    "    _thresholds = []\n",
    "    score_dict = {}\n",
    "    label_dict = {}\n",
    "    \n",
    "    # for each hosp_id, extract a list of monotonically increasing scores\n",
    "    for _, row in df.iterrows():\n",
    "        _pid = row[\"hosp_id\"]\n",
    "        label_dict[_pid] = float(row[\"y\"])\n",
    "        _scores = row[\"y_scores_mcures_lst_eval1\"]\n",
    "        _thresholds += _scores\n",
    "        i = _scores[0]\n",
    "        monotonic_scores = [i]\n",
    "        if len(_scores) > 1:\n",
    "            for j in _scores[1:]:\n",
    "                if j > i:\n",
    "                    monotonic_scores.append(j)\n",
    "                    i = j\n",
    "        score_dict[_pid] = monotonic_scores\n",
    "    \n",
    "    # list of decision thresholds\n",
    "    thresholds = _thresholds if thresholds is None else thresholds    \n",
    "    thresholds = set(thresholds)\n",
    "    thresholds.update({0,1})\n",
    "    thresholds = sorted(thresholds)\n",
    "    thresholded_score_dict = copy.deepcopy(score_dict)\n",
    "    \n",
    "    # for each hosp_id, extract the y label\n",
    "    label_list = []\n",
    "    for pid, _ in thresholded_score_dict.items():\n",
    "        label_list.append(label_dict[pid])\n",
    "    \n",
    "    # calculate per-threshold calibration ece score\n",
    "    scores_arr = []\n",
    "    for threshold in thresholds:\n",
    "        score_list = []\n",
    "        for pid, scores in thresholded_score_dict.items():\n",
    "            if len(scores) > 1:\n",
    "                _scores = [i for i in scores if i>=threshold]\n",
    "                thresholded_score_dict[pid] = _scores\n",
    "            first_score = thresholded_score_dict[pid][0]\n",
    "            score_list.append(first_score)\n",
    "        scores_arr.append(score_fx(label_list, score_list))\n",
    "        \n",
    "    if given_thresholds is None:\n",
    "        return thresholds, scores_arr\n",
    "    else: \n",
    "        return scores_arr\n",
    "    \n",
    "def bootstrap_ece(i, function, df, thresholds):\n",
    "    while True:\n",
    "        try:\n",
    "            df_resample = df.sample(frac=1, replace=True, random_state=i)\n",
    "            return fsgte(function, df_resample, thresholds)\n",
    "        except: \n",
    "            i += 1000\n",
    "    return\n",
    "\n",
    "def get_ece_CI(df):\n",
    "    thresholds, scores = fsgte(calibration_curve_ece, master)\n",
    "    ece_curves = np.array(Parallel(n_jobs=50)(delayed(bootstrap_ece)(i, calibration_curve_ece, df, thresholds) for i in range(100)))\n",
    "    auece_scores = [metrics.auc(thresholds, x) for x in ece_curves]\n",
    "    eces_med, eces_lower, eces_upper = np.percentile(ece_curves, 50, axis=0), np.percentile(ece_curves, 2.5, axis=0), np.percentile(ece_curves, 97.5, axis=0)\n",
    "    return ece_curves, auece_scores, thresholds, eces_med, eces_lower, eces_upper\n",
    "\n",
    "from sklearn.preprocessing import label_binarize \n",
    "\n",
    "def calibration_curve(y_true, y_prob, *, normalize=False, n_bins=5,\n",
    "                      strategy='uniform'):\n",
    "    y_true = np.array(y_true)\n",
    "    y_prob = np.array(y_prob)\n",
    "\n",
    "    if normalize:  # Normalize predicted values into interval [0, 1]\n",
    "        y_prob = (y_prob - y_prob.min()) / (y_prob.max() - y_prob.min())\n",
    "    elif y_prob.min() < 0 or y_prob.max() > 1:\n",
    "        raise ValueError(\"y_prob has values outside [0, 1] and normalize is \"\n",
    "                         \"set to False.\")\n",
    "\n",
    "    labels = np.unique(y_true)\n",
    "    if len(labels) > 2:\n",
    "        raise ValueError(\"Only binary classification is supported. \"\n",
    "                         \"Provided labels %s.\" % labels)\n",
    "    y_true = label_binarize(y_true, classes=labels)[:, 0]\n",
    "\n",
    "    if strategy == 'quantile':  # Determine bin edges by distribution of data\n",
    "        quantiles = np.linspace(0, 1, n_bins + 1)\n",
    "        bins = np.percentile(y_prob, quantiles * 100)\n",
    "        bins[-1] = bins[-1] + 1e-8\n",
    "    elif strategy == 'uniform':\n",
    "        bins = np.linspace(0., 1. + 1e-8, n_bins + 1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid entry to 'strategy' input. Strategy \"\n",
    "                         \"must be either 'quantile' or 'uniform'.\")\n",
    "\n",
    "    binids = np.digitize(y_prob, bins) - 1\n",
    "\n",
    "    bin_sums = np.bincount(binids, weights=y_prob, minlength=len(bins))\n",
    "    bin_true = np.bincount(binids, weights=y_true, minlength=len(bins))\n",
    "    bin_total = np.bincount(binids, minlength=len(bins))\n",
    "\n",
    "    nonzero = bin_total != 0\n",
    "    prob_true = bin_true[nonzero] / bin_total[nonzero]\n",
    "    prob_pred = bin_sums[nonzero] / bin_total[nonzero]\n",
    "\n",
    "    return prob_true, prob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1 Information\n",
    "\n",
    "y_true, y_score = master['y'], master['y_score_mcures']\n",
    "combine_all_scores = [x for x in master[\"y_scores_mcures_lst_eval1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC\n",
    "fpr, tpr, roc_thresholds = metrics.roc_curve(y_true, y_score)\n",
    "roc_curves, auroc_scores, mean_fpr, tprs_lower, tprs_upper = get_roc_CI(y_true, y_score)\n",
    "\n",
    "# PR\n",
    "prec, rec, pr_thresholds = metrics.precision_recall_curve(y_true, y_score)\n",
    "pr_curves, aupr_scores, mean_rec, prec_lower, prec_upper = get_pr_CI(y_true, y_score)\n",
    "\n",
    "# Calibration\n",
    "# combine_all_scores = df_plot['all_predictions'].iloc[i]\n",
    "all_ys = [[y_true[i]] * len(combine_all_scores[i]) for i in range(len(y_true))]\n",
    "flat_ys = [item for sublist in all_ys for item in sublist]\n",
    "flat_scores = [item for sublist in combine_all_scores for item in sublist]\n",
    "P_true, P_pred = calibration_curve(flat_ys, flat_scores, strategy = 'quantile')\n",
    "ece_score = np.mean(np.square(np.array(P_true) - np.array(P_pred)))\n",
    "P_trues, P_preds = get_calibs(combine_all_scores, all_ys)\n",
    "ece_scores = np.mean(np.square(np.array(P_trues) - np.array(P_preds)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2\n",
    "\n",
    "months1 = ['3/20', '4/20', '5/20']\n",
    "months2 = ['6/20', '7/20', '8/20']\n",
    "months3 = ['9/20', '10/20', '11/20']\n",
    "months4 = ['12/20', '1/21', '2/21']\n",
    "\n",
    "Ns, percs, aurocs, auprs = [], [], [], []\n",
    "for chunks in [months1, months2, months3, months4]: \n",
    "    df = master[master['admission_date'].isin(chunks)]\n",
    "    N, perc = len(df['y']), np.mean(df['y'])\n",
    "    Ns.append(N)\n",
    "    percs.append(perc)\n",
    "    \n",
    "    if N > 25 and perc > 0 and perc < 1: \n",
    "        (_, _), (all_rocs, roc), (all_prs, pr) = get_nums(df)\n",
    "        aurocs.append((all_rocs, roc))\n",
    "        auprs.append((all_prs, pr))\n",
    "    else: \n",
    "        aurocs.append([[0], 0])\n",
    "        auprs.append([[0], 0])\n",
    "\n",
    "all_months = months1 + months2 + months3 + months4\n",
    "\n",
    "Ns_months, percs_months, aurocs_months, auprs_months = [], [], [], []\n",
    "for chunks in all_months: \n",
    "    df = master[master['admission_date'].isin([chunks])]\n",
    "    N, perc = len(df['y']), np.mean(df['y'])\n",
    "    Ns_months.append(N)\n",
    "    percs_months.append(perc)\n",
    "    \n",
    "    if N > 25 and perc > 0 and perc < 1:\n",
    "        (_, _), (all_rocs, roc), (all_prs, pr) = get_nums(df)\n",
    "        aurocs_months.append((all_rocs, roc))\n",
    "        auprs_months.append((all_prs, pr))\n",
    "    else:\n",
    "        aurocs_months.append([[0], 0])\n",
    "        auprs_months.append([[0], 0])\n",
    "    \n",
    "figure2_results = {\n",
    "    # Across months\n",
    "    'by_months-Ns': Ns,\n",
    "    'by_months-percs': percs,\n",
    "    'by_months-aurocs': aurocs,\n",
    "    'by_months-auprs': auprs,\n",
    "    'granular-Ns': Ns_months, \n",
    "    'granular-percs': percs_months, \n",
    "    'granular-aurocs': aurocs_months, \n",
    "    'granular-auprs': auprs_months\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_quarter_names = []\n",
    "\n",
    "for chunks in [months1, months2, months3, months4]:\n",
    "    by_quarter_names.append('Quarter:'+str(chunks))\n",
    "    \n",
    "by_month_names = []\n",
    "for month in all_months:\n",
    "    by_month_names.append('Month:'+month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "# Across Demographic Subgroups\n",
    "by_demog_names = []\n",
    "by_demog_Ns = []\n",
    "by_demog_percs = []\n",
    "by_demog_aurocs = []\n",
    "by_demog_auprs = []\n",
    "\n",
    "# Sex\n",
    "for sex in tqdm(np.unique(master['sex']), desc='Sex'):\n",
    "    df = master[master['sex'] == sex]\n",
    "    N, perc = len(df['y']), np.mean(df['y'])\n",
    "    by_demog_names.append('Sex:'+sex)\n",
    "    by_demog_Ns.append(N)\n",
    "    by_demog_percs.append(perc)\n",
    "\n",
    "    if N > 25 and perc > 0 and perc < 1:\n",
    "        (_, _), (all_rocs, roc), (all_prs, pr) = get_nums(df)\n",
    "        by_demog_aurocs.append((all_rocs, roc))\n",
    "        by_demog_auprs.append((all_prs, pr))\n",
    "    else:\n",
    "        by_demog_aurocs.append([[0], 0])\n",
    "        by_demog_auprs.append([[0], 0])\n",
    "\n",
    "\n",
    "# Age\n",
    "age_groups = [[17, 25], [25, 45], [45, 65], [65, 85], [85, 1000]]\n",
    "\n",
    "for age_lower, age_upper in tqdm(age_groups, desc='Age'):\n",
    "    df = master[(age_lower < master['age']) & (master['age'] <= age_upper)]\n",
    "    N, perc = len(df['y']), np.mean(df['y'])\n",
    "    by_demog_names.append('Age:{}-{}'.format(age_lower, age_upper))\n",
    "    by_demog_Ns.append(N)\n",
    "    by_demog_percs.append(perc)\n",
    "\n",
    "    if N > 25 and perc > 0 and perc < 1:\n",
    "        (_, _), (all_rocs, roc), (all_prs, pr) = get_nums(df)\n",
    "        by_demog_aurocs.append((all_rocs, roc))\n",
    "        by_demog_auprs.append((all_prs, pr))\n",
    "    else:\n",
    "        by_demog_aurocs.append([[0], 0])\n",
    "        by_demog_auprs.append([[0], 0])\n",
    "\n",
    "# Race\n",
    "master['race_category'] = master['race'].replace(\n",
    "    ['African American', 'Caucasian', np.nan, 'Patient Refused', 'Unknown', 'American Indian or Alaska Native', 'Native Hawaiian and Other Pacific Islander', 'More than 1'],\n",
    "    ['Black', 'White', 'Other', 'Other', 'Other', 'Other', 'Other', 'More than 1']).fillna('Other')\n",
    "\n",
    "for race in tqdm(np.unique(master['race_category']), desc='Race'): \n",
    "    df = master[master['race_category'] == race]\n",
    "    N, perc = len(df['y']), np.mean(df['y'])\n",
    "    by_demog_names.append('Race:'+race)\n",
    "    by_demog_Ns.append(N)\n",
    "    by_demog_percs.append(perc)\n",
    "\n",
    "    if N > 25 and perc > 0 and perc < 1:\n",
    "        (_, _), (all_rocs, roc), (all_prs, pr) = get_nums(df)\n",
    "        by_demog_aurocs.append((all_rocs, roc))\n",
    "        by_demog_auprs.append((all_prs, pr))\n",
    "    else:\n",
    "        by_demog_aurocs.append([[0], 0])\n",
    "        by_demog_auprs.append([[0], 0])\n",
    "\n",
    "# Ethnicity\n",
    "ethnicities = [\n",
    "    'Ethnicity:Hispanic',\n",
    "    'Ethnicity:Non-Hispanic',\n",
    "    'Ethnicity:Unknown',\n",
    "]\n",
    "\n",
    "master['ethnicity_category'] = master['ethnicity'].replace(\n",
    "    ['Hispanic or Latino', 'Non-Hispanic or Latino', 'Unknown', 'Patient Refused'],\n",
    "    ['Ethnicity:Hispanic','Ethnicity:Non-Hispanic','Ethnicity:Unknown', 'Ethnicity:Unknown']).fillna('Ethnicity:Unknown')\n",
    "\n",
    "\n",
    "for ethnicity in tqdm(np.unique(master['ethnicity_category']), desc='Ethnicity'): \n",
    "    df = master[master['ethnicity_category'] == ethnicity]\n",
    "    N, perc = len(df['y']), np.mean(df['y'])\n",
    "    by_demog_names.append(ethnicity)\n",
    "    by_demog_Ns.append(N)\n",
    "    by_demog_percs.append(perc)\n",
    "\n",
    "    if N > 25 and perc > 0 and perc < 1:\n",
    "        (_, _), (all_rocs, roc), (all_prs, pr) = get_nums(df)\n",
    "        by_demog_aurocs.append((all_rocs, roc))\n",
    "        by_demog_auprs.append((all_prs, pr))\n",
    "    else:\n",
    "        by_demog_aurocs.append([[0], 0])\n",
    "        by_demog_auprs.append([[0], 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_demog_names, by_demog_Ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 4 -- Secondary Use-Case\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "def bootstrap_fn(i, df, replace = True, val = 48):\n",
    "    df_Yte_agg = df.sample(frac = 1, replace=replace, random_state=i)\n",
    "    \n",
    "    scores = np.sort(df_Yte_agg['secondary_mcures'])\n",
    "    \n",
    "    #Find highest threshold with NPV >= 0.95\n",
    "    for s in scores: \n",
    "        curr = df_Yte_agg[df_Yte_agg['secondary_mcures'] <= s]\n",
    "        if 1 - curr['y_secondary'].mean() >= 0.95: \n",
    "            latest = curr\n",
    "    try: \n",
    "        #Percentage of people discharged\n",
    "        discharged = latest.shape[0] / len(scores)\n",
    "        num = latest.shape[0]\n",
    "        #Total number of days spent in the hospital - 2 days -- amount of potential time saved on these examples \n",
    "        total_days = np.sum((latest['final_time_min'] / (60 * 24)) - (val / 24))\n",
    "\n",
    "    except: \n",
    "        return 0, 0\n",
    "    \n",
    "    return discharged, total_days\n",
    "\n",
    "\n",
    "def get_roc_CI(df, val):\n",
    "    discharged, days = zip(*Parallel(n_jobs=10)(delayed(bootstrap_fn)(i, df, val) for i in range(1000)))\n",
    "    return discharged, days\n",
    "\n",
    "    \n",
    "secondary = master[master['in_second_use_case'] == True]\n",
    "\n",
    "import time \n",
    "\n",
    "now = time.time() \n",
    "\n",
    "discharged, days = get_roc_CI(secondary, 48)\n",
    "\n",
    "print(time.time() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_results = []\n",
    "D_results.append({\n",
    "    # Name of the institution\n",
    "    'Institution': institution,\n",
    "    \n",
    "    \n",
    "    ### Figure 1: ROC, PR, Calibration\n",
    "    # Saves the performance metrics and all the points on each curve, including 95% confidence intervals\n",
    "    \n",
    "    # ROC\n",
    "    'roc_curve': [list(fpr), list(tpr), list(roc_thresholds)],\n",
    "    'roc_curve_CI': [list(mean_fpr), list(tprs_lower), list(tprs_upper)],\n",
    "    'auroc_score': metrics.roc_auc_score(y_true, y_score),\n",
    "    'auroc_score_CI': [np.percentile(auroc_scores, 2.5), np.percentile(auroc_scores, 97.5)],\n",
    "    'auroc_score_bootstrapped': list(auroc_scores),\n",
    "\n",
    "    # PR\n",
    "    'pr_curve': [list(prec), list(rec), list(pr_thresholds)],\n",
    "    'pr_curve_CI': (list(mean_rec), list(prec_lower), list(prec_upper)),\n",
    "    'aupr_score': metrics.auc(*metrics.precision_recall_curve(y_true, y_score)[1::-1]),\n",
    "    'aupr_score_CI': [np.percentile(aupr_scores, 2.5), np.percentile(aupr_scores, 97.5)], \n",
    "    'aupr_score_bootstrapped': list(aupr_scores),\n",
    "\n",
    "    # Calibration\n",
    "    'calibration_curve': [list(P_true), list(P_pred)],\n",
    "    'calibration_curve_bootstrapped': [np.array(P_trues).tolist(), np.array(P_preds).tolist()],\n",
    "    'ece_score': ece_score,\n",
    "    'ece_score_CI': [np.percentile(ece_scores, 2.5), np.percentile(ece_scores, 97.5)], \n",
    "    'ece_score_bootstrapped': list(ece_scores),\n",
    "    \n",
    "    \n",
    "    ### Figures 2-3: Subgroup analyses\n",
    "    # only summary statistics and performance metrics are saved\n",
    "    # only generate results if N>25 for a subgroup\n",
    "    \n",
    "    # Figure 2A: Across months\n",
    "    'by_month_names': by_month_names,          # descriptive name for each group\n",
    "    'by_month_Ns': Ns_months,                  # sample size for each group\n",
    "    'by_month_percs': percs_months,            # outcome rates for each group\n",
    "    'by_month_aurocs': aurocs_months,          # (list of bootstrap scores, non-bootstrapped score)\n",
    "    'by_month_auprs': auprs_months,\n",
    "    \n",
    "    # Figure 2B: Across quarters\n",
    "    'by_quarter_names': by_quarter_names,      # [\"Quarter:['3/20', '4/20', '5/20']\", \"Quarter:['6/20', '7/20', '8/20']\", \"Quarter:['9/20', '10/20', '11/20']\", \"Quarter:['12/20', '1/21', '2/21']\"]\n",
    "    'by_quarter_Ns': Ns,\n",
    "    'by_quarter_percs': percs,\n",
    "    'by_quarter_aurocs': aurocs,\n",
    "    'by_quarter_auprs': auprs,\n",
    "    \n",
    "    # Figure 3: Across demographics            \n",
    "    'by_demog_names': by_demog_names,          # ['Sex:F', 'Sex:M', 'Age:17-25', 'Age:25-45', 'Age:45-65', 'Age:65-85', 'Age:85-1000', 'Race:Asian', 'Race:Black', 'Race:Other', 'Race:White', 'Ethnicity:Hispanic', 'Ethnicity:Non-Hispanic', 'Ethnicity:Unknown']\n",
    "    'by_demog_Ns': by_demog_Ns,\n",
    "    'by_demog_percs': by_demog_percs,\n",
    "    'by_demog_aurocs': by_demog_aurocs,\n",
    "    'by_demog_auprs': by_demog_auprs,\n",
    "    \n",
    "    \n",
    "    ### Figure 4: Secondary use case, 1000 bootstrapped values\n",
    "    # saves two lists of 1000 numbers\n",
    "    'days_saved_boostraps': list(days),        # Potential bed days saved (length of stay - 2 days)\n",
    "    'discharged_boostrap': list(discharged),   # Percentage discharged (num people less than decision threshold at which NPV >= 95%)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for rounding numbers in nested list\n",
    "def round_nested_list(lst, num=3):\n",
    "    if isinstance(lst, str) or isinstance(lst, int):\n",
    "        return lst\n",
    "    elif isinstance(lst, float):\n",
    "        return round(lst, num) # '%.{}f'.format(num) %lst\n",
    "    else:\n",
    "        return [round_nested_list(i) for i in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(D_results)\n",
    "\n",
    "# Round all numbers to 3 decimal places\n",
    "for col in df_results.columns:\n",
    "    df_results[col] = df_results[col].apply(round_nested_list)\n",
    "\n",
    "df_results.to_csv('{}-RESULTS.csv'.format(institution), index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
